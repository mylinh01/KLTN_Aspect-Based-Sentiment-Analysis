{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from gensim.utils import simple_preprocess\n",
    "import pandas as pd\n",
    "from nltk import flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "from tensorflow.train import CheckpointOptions, latest_checkpoint\n",
    "from tensorflow.data import Dataset\n",
    "from transformers import TFAutoModel\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import pickle \n",
    "from preprocess import text_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFRobertaModel, AdamWeightDecay\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'TFRobertaModel': TFRobertaModel})\n",
    "tf.keras.utils.get_custom_objects().update({'AdamWeightDecay': AdamWeightDecay})\n",
    "\n",
    "model = tf.keras.models.load_model('E:/KLTN/ABSA/model/bert.h5', custom_objects={\"AdamWeightDecay\": AdamWeightDecay})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inputs, batch_size = 1, verbose = 0):\n",
    "    y_pred = model.predict(inputs, batch_size = batch_size, verbose = verbose)\n",
    "    y_pred = y_pred.reshape(len(y_pred), -1, 4)\n",
    "    return np.argmax(y_pred, axis=-1) # sentiment values (position that have max value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acsa_pred(replacements, categories, sentence_pred):\n",
    "    sentiments = map(lambda x: replacements[x], sentence_pred)\n",
    "    for category, sentiment in zip(categories, sentiments):\n",
    "        if sentiment: print(f'=> {category},{sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"quán đẹp, đồ ăn ngon nhưng nhân viên phục vụ thái độ không tốt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {0: None, 1: 'positive', 2: 'negative', 3: 'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'AMBIENCE#GENERAL',\t'DRINKS#PRICES',\t'DRINKS#QUALITY',\t'DRINKS#STYLE&OPTIONS',\n",
    "          'FOOD#PRICES',\t'FOOD#QUALITY',\t'FOOD#STYLE&OPTIONS', 'LOCATION#GENERAL',\n",
    "\t\t\t\t\t'RESTAURANT#GENERAL',\t'RESTAURANT#MISCELLANEOUS',\t'RESTAURANT#PRICES',\t'SERVICE#GENERAL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 'vinai/phobert-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vinai/phobert-base': 256, 'vinai/phobert-large': 256}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> RESTAURANT#GENERAL,positive\n",
      "=> LOCATION#GENERAL,positive\n"
     ]
    }
   ],
   "source": [
    "example_input = text_preprocess(input_text)\n",
    "tokenized_input = tokenizer(example_input, padding='max_length', truncation=True)\n",
    "features = {x: [[tokenized_input[x]]] for x in tokenizer.model_input_names}\n",
    "\n",
    "pred = predict(model, Dataset.from_tensor_slices(features))\n",
    "print_acsa_pred(replacements, categories, pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "rdrsegmenter = VnCoreNLP(\"VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
